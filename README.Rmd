---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  error = FALSE,
  comment = "#>"
)
```



# Análise do Doutorado

## Carregando os pacotes
```{r}
library(tidymodels)
library(tidyverse)
library(patchwork)
library(ggspatial)
library(modeldata)
library(ggridges)
library(readxl)
library(fco2r)
library(skimr)
library(ISLR)
library(vip)
```


## Lendo o Banco de dados
```{r}
anomalias <- readr::read_rds("data/anomalias.rds")
glimpse(anomalias)
```

## FAZER O RIDGE AQUI...

```{r}
anomalias %>% 
  mutate(
    fct_ano = fct_rev(as.factor(ano)),
    classe = ifelse(tratamento == "UC_desm" | tratamento == "TI_desm",
                    "Des","Con")
    ) %>% 
  ggplot(aes(y=fct_ano)) +
  geom_density_ridges(rel_min_height = 0.03,
    aes(x=xco2, fill=classe),
    alpha = .6, color = "black", from = 395, to = 413
    ) +
  scale_fill_cyclical(values = c("#238B45","#ff8080"),
                      name = "classe", guide = "legend") +
  theme_ridges() 
```

```{r}
anomalias %>% 
  mutate(
    fct_ano = fct_rev(as.factor(ano)),
    classe = ifelse(tratamento == "UC_desm" | tratamento == "TI_desm",
                    "Des","Con")
    ) %>% 
  ggplot(aes(y=fct_ano)) +
  geom_density_ridges(rel_min_height = 0.03,
    aes(x=anomalia, fill=classe),
    alpha = .6, color = "black", from = -10, to = 10
    ) +
  scale_fill_cyclical(values = c("#238B45","#ff8080"),
                      name = "classe", guide = "legend") +
  theme_ridges() 
```


## lendo a Base para o Aprendizado de Máquina
```{r}
data_set_ml <- anomalias %>% 
  mutate(
    fct_ano = fct_rev(as.factor(ano)),
    classe = as_factor(ifelse(tratamento == "UC_desm" | tratamento == "TI_desm",
                    "Des","Con")
    )) %>% #<-------
  drop_na()
classe_initial_split <- initial_split(data_set_ml, prop = 0.75,
                                      strata = classe)
```


```{r}
classe_train <- training(classe_initial_split)
# fco2_test <- testing(fco2_initial_split)
# visdat::vis_miss(fco2_test)
classe_train  %>% 
  ggplot(aes(x=xco2, y=..density..))+
  geom_histogram(bins = 30, color="black",  fill="lightgray")+
  geom_density(alpha=.05,fill="red")+
  theme_bw() +
  labs(x="xco2 - treino", y = "Densidade")

classe_train  %>% 
  ggplot(aes(x=sif, y=..density..))+
  geom_histogram(bins = 30, color="black",  fill="lightgray")+
  geom_density(alpha=.05,fill="red")+
  theme_bw() +
  labs(x="sif - treino", y = "Densidade")

classe_train  %>% 
  ggplot(aes(x=ndvi, y=..density..))+
  geom_histogram(bins = 30, color="black",  fill="lightgray")+
  geom_density(alpha=.05,fill="red")+
  theme_bw() +
  labs(x="ndvi - treino", y = "Densidade")


classe_train  %>% 
  ggplot(aes(x=lai, y=..density..))+
  geom_histogram(bins = 30, color="black",  fill="lightgray")+
  geom_density(alpha=.05,fill="red")+
  theme_bw() +
  labs(x="lai - treino", y = "Densidade")


classe_train  %>% 
  ggplot(aes(x=lst_amp, y=..density..))+
  geom_histogram(bins = 30, color="black",  fill="lightgray")+
  geom_density(alpha=.05,fill="red")+
  theme_bw() +
  labs(x="lst_amp - treino", y = "Densidade")
```

```{r}
classe_recipe <- recipe(classe ~ ., 
                      data = classe_train %>% 
            select(classe, xco2:lst_amp) 
) %>%  
  # step_normalize(all_numeric_predictors())  %>% 
#  step_naomit() %>%  
  step_novel(all_nominal_predictors()) %>% 
  step_zv(all_predictors()) %>%
 # step_naomit(c(ts, us)) %>% 
  #step_impute_median(where(is.numeric)) %>% # inputação da mediana nos numéricos
  # step_poly(c(Us,Ts), degree = 2)  %>%  
  step_dummy(all_nominal_predictors())
bake(prep(classe_recipe), new_data = NULL)
```

```{r}
visdat::vis_miss(bake(prep(classe_recipe), new_data = NULL))
```

### RNA

```{r}
classe_nn_model <- mlp(
  hidden_units = 2) %>% # margin sempre para regressão
  set_mode("classification") %>%
  set_engine("nnet") %>% 
  fit(classe ~ ., data = classe_train %>% 
            select(classe, xco2:lst_amp))
NeuralNetTools::plotnet(classe_nn_model$fit)
classe_resamples <- vfold_cv(classe_train, v = 5)
```

```{r}
classe_nn_model <- mlp(
  hidden_units = tune(), 
  penalty = tune(),
  epochs = tune()
  ) %>% # margin sempre para regressão
  set_mode("classification") %>%
  set_engine("nnet") 
```

```{r}
classe_nn_wf <- workflow()   %>%  
  add_model(classe_nn_model) %>% 
  add_recipe(classe_recipe)
```

```{r}
grid_nn <- expand.grid(
  hidden_units = c(1,2),
  penalty = c(1,5),
  epochs = c(50, 100)
)
glimpse(grid_nn)
```

```{r}
classe_nn_tune_grid <- tune_grid(
  classe_nn_wf,
  resamples = classe_resamples,
  grid = grid_nn,
  metrics = metric_set(roc_auc)
)
```

```{r}
area_nn <- collect_metrics(classe_nn_tune_grid)  %>%  
  filter(.metric == "roc_auc")  %>%  
  summarise(area = mean(mean),
            desvio_pad = mean(std_err))
```

```{r}
autoplot(classe_nn_tune_grid)
```

```{r}
classe_nn_best_params <- select_best(classe_nn_tune_grid, "roc_auc")
classe_nn_wf <- classe_nn_wf  %>%  finalize_workflow(classe_nn_best_params)

classe_nn_last_fit <- last_fit(
  classe_nn_wf,
  classe_initial_split
)

# Variáveis importantes
classe_nn_last_fit_model <-classe_nn_last_fit$.workflow[[1]]$fit$fit
vip(classe_nn_last_fit_model,
    aesthetics = list(color = "black", fill = "orange")) +
    theme(axis.text.y=element_text(size=rel(1.5)),
          axis.text.x=element_text(size=rel(1.5)),
          axis.title.x=element_text(size=rel(1.5))
          ) +
  theme_bw()
```

```{r}
classe_test_preds_nn <- collect_predictions(classe_nn_last_fit)
classe_roc_curve_nn <- classe_test_preds_nn %>%
  roc_curve(classe, .pred_Con)
autoplot(classe_roc_curve_nn)
```

